{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3354b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### I need to understand what are we trying to do\n",
    "# Then code it with the three techniques\n",
    "# finally understand the purpose of all the models....!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ac33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9693c392",
   "metadata": {},
   "source": [
    "# Bugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fc47d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First we create df from the iris\n",
    "#### then we need to cut or filter some features from the df  e.g get 100 data from the 150\n",
    "#### then we alter the dataFrame by doing randomization the 100 data \n",
    "# for the bagging technique we split the data to train_data and test\n",
    "\n",
    "#### from the train_data we slice to train(60%) and test(40%)\n",
    "#### and we shuffle or sample 10 from each for the train data\n",
    "\n",
    "#### then from the 10 we suffle or sample 8 for X_train and y_train\n",
    "#### and also suffle 5 for the X_test and y_test\n",
    "# Now train the DT model cuz it is the for bugging Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f96aac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### First we create df from the iris\n",
    "iris = datasets.load_iris()\n",
    "#iris.target_names, \" \", iris.feature_names, \" \", iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524a43b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fd1e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>petal length</th>\n",
       "      <th>spices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  petal length  spices\n",
       "0           3.2           4.7       1\n",
       "1           3.2           4.5       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### then we need to cut or filter some features from the df  e.g get 100 data from the 150\n",
    "\n",
    "#### we can use 100 of the whole iris data\n",
    "#### use only the two features ----> [ versicolor', 'virginica ]\n",
    "#### [0 is ->'setosa', 1 is ->'versicolor', 2 is ->'virginica']\n",
    "\n",
    "new_data = {\n",
    "    'sepal length': iris.data[50:, 1], # from 50 to 150 but only at the sepal-length(index 1)\n",
    "    'petal length': iris.data[50:, 2], # from 50 to 150 but only at the sepal-length(index 2)\n",
    "    'spices': np.array([i for i in iris.target if i > 0]) #means only [versicolor','virginica]\n",
    "}\n",
    "\n",
    "df2 = pd.DataFrame(new_data)\n",
    "print(df2.shape)\n",
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c419f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2559c4d6",
   "metadata": {},
   "source": [
    "## !!! Need to randomize or shuffle the df --- cuz that's how bagging works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47aad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df_train >>> 10 len of df_test >>> 10\n"
     ]
    }
   ],
   "source": [
    "#### then we alter the dataFrame by doing randomization the 100 data \n",
    "# for the bagging technique we split the data to train_data(60) and test_data(40) and randomize it with 10\n",
    "df2 = df2.sample(df2.shape[0])\n",
    "\n",
    "X = df2.iloc[:60].sample(10)\n",
    "y = df2.iloc[61:].sample(10)\n",
    "print(f\"len of df_train >>> {len(X)}\", f\"len of df_test >>> {len(y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7ea3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b581b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### from the train_data we sliced to train(60%) and test(40%)\n",
    "#### and we shuffle or sample 10 from each for the train data\n",
    "#### Generate the X_train, X_tes, y_tarin, y_test from the dataFORtrain and dataFORtest\n",
    "\n",
    "\n",
    "########### X_train and y_tarin #############\n",
    "#### .values will give you an array\n",
    "#### Now let's take 8 values from the 10 and provide it as an input\n",
    "trainer_data = X.sample(8, replace=True)\n",
    "X_train = trainer_data.iloc[:, :-1].values\n",
    "y_train = trainer_data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "\n",
    "########### X_test, y_test #############\n",
    "tester_data = y.sample(5, replace=True)\n",
    "X_test = tester_data.iloc[:, :-1].values\n",
    "y_test = tester_data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ebd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fe24ea2",
   "metadata": {},
   "source": [
    "# 1st DecisionTreeClassifier......... Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85a8e777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train the DT model cuz it is the for bugging Technique\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0fafe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train.. >>> 100.0\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "pred_train = model.predict(X_train)\n",
    "acc_train = accuracy_score(y_train, pred_train)\n",
    "print('acc_train.. >>>', acc_train * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d28e638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_test.. >>> 100.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_test, y_test)\n",
    "pred_test = model.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, pred_test)\n",
    "print('acc_test.. >>>', acc_test * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169aa13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e45f6548",
   "metadata": {},
   "source": [
    "# 2nd DecisionTreeClassifier......... Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55868227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accu : 100.0\n",
      "y_test : [1 2 2 1 2]\n",
      "sec_pred : [1 2 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "second_model = DecisionTreeClassifier()\n",
    "\n",
    "# get 8 randomize data from the 60 and 5 from the 40\n",
    "#### Now let's take 8 values from the 10 and provide it as an input\n",
    "trainer_data = X.sample(8, replace=True)\n",
    "X_train = trainer_data.iloc[:, :-1].values\n",
    "y_train = trainer_data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "########### X_test, y_test #############\n",
    "tester_data = y.sample(5, replace=True)\n",
    "X_test = tester_data.iloc[:, :-1].values\n",
    "y_test = tester_data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "second_model.fit(X_train, y_train)\n",
    "sec_pred = second_model.predict(X_test)\n",
    "acc_sec = accuracy_score(y_test, sec_pred)\n",
    "\n",
    "print(f\"accu : {acc_sec * 100}\")\n",
    "print(f\"y_test : {y_test}\")\n",
    "print(f\"sec_pred : {sec_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6c1aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36a4fd7b",
   "metadata": {},
   "source": [
    "# 3rd DecisionTreeClassifier......... Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd41521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accu : 60.0\n",
      "y_test : [2 1 1 2 1]\n",
      "third_pred : [2 2 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "third_model = DecisionTreeClassifier()\n",
    "\n",
    "# get 8 randomize data from the 60 and 5 from the 40\n",
    "#### Now let's take 8 values from the 10 and provide it as an input\n",
    "trainer_data = X.sample(8, replace=True)\n",
    "X_train = trainer_data.iloc[:, :-1].values\n",
    "y_train = trainer_data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "########### X_test, y_test #############\n",
    "tester_data = y.sample(5, replace=True)\n",
    "X_test = tester_data.iloc[:, :-1].values\n",
    "y_test = tester_data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "third_model.fit(X_train, y_train)\n",
    "third_pred = third_model.predict(X_test)\n",
    "acc_third = accuracy_score(y_test, third_pred)\n",
    "\n",
    "print(f\"accu : { acc_third * 100}\")\n",
    "print(f\"y_test : {y_test}\")\n",
    "print(f\"third_pred : {third_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15b26a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3c5de48",
   "metadata": {},
   "source": [
    "# We've created 3 individual models on the above\n",
    "#### Try it now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32461b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[2]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "#### Bagging technique is this -> when you get d/t result with the same data, then you pick the more repeated one.\n",
    "print(model.predict(np.array([2.5, 5.0]).reshape(1, -1)))\n",
    "print(second_model.predict(np.array([2.5, 5.0]).reshape(1, -1)))\n",
    "print(third_model.predict(np.array([2.5, 5.0]).reshape(1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871dc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "778bedca",
   "metadata": {},
   "source": [
    "# Voting / stacking\n",
    "#### basicly we do NOT need to use randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a520bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### We need to import few moels and create VotingClassifier model.... then train them with the unradomized data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "m1 = KNeighborsClassifier()\n",
    "m2 = LogisticRegression()\n",
    "m3 = MultinomialNB()\n",
    "m4 = GaussianNB()\n",
    "m5 = DecisionTreeClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770f3e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_xxTrain:- >> 0.9142857142857143\n",
      "acc_xxTest...:- >> 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "all_models = VotingClassifier([('knn', m1), ('Lg', m1), ('mn', m3), ('gn', m4), ('dt', m5)])\n",
    "\n",
    "XX = df2.iloc[:, :-1].values\n",
    "yy = df2.iloc[:, -1].values\n",
    "\n",
    "XX_train, XX_test, yy_train, yy_test = train_test_split(XX, yy, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "##############  Train ####################\n",
    "all_models.fit(XX_train, yy_train)\n",
    "pred_yyTrain = all_models.predict(XX_train)\n",
    "acc_xxTrain = accuracy_score(yy_train, pred_yyTrain)\n",
    "print(f\"acc_xxTrain:- >> {acc_xxTrain}\")\n",
    "\n",
    "\n",
    "##############  Test  ####################\n",
    "all_models.fit(XX_test, yy_test)\n",
    "pred_yyTest = all_models.predict(XX_test)\n",
    "acc_xxTest = accuracy_score(yy_test, pred_yyTest)\n",
    "print(f\"acc_xxTest...:- >> {acc_xxTest}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7c527da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECOND OPTION .... shorter than the above\n",
    "# yTrainPred = all_models.score(XX_train, yy_train)\n",
    "# print(yTrainPred * 100)\n",
    "\n",
    "# yTestPred = all_models.score(XX_test, yy_test)\n",
    "# print(yTestPred * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cdfa53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e30e0cd",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "### One of the best boosting technique is AdaBoostClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dd6ad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc_accTrain :- >> 0.9285714285714286\n",
      "abc_accTest :- >> 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "abc = AdaBoostClassifier(n_estimators=4, random_state=0)\n",
    "\n",
    "\n",
    "##############  Train  ####################\n",
    "abc.fit(XX_train, yy_train)\n",
    "pred_abcTrain = abc.predict(XX_train)\n",
    "abc_accTrain = accuracy_score(yy_train, pred_abcTrain)\n",
    "print(f\"abc_accTrain :- >> {abc_accTrain}\")\n",
    "\n",
    "\n",
    "##############  Test  ####################\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(XX_test, yy_test)\n",
    "pred_abcTest = abc.predict(XX_test)\n",
    "abc_accTest = accuracy_score(yy_test, pred_abcTest)\n",
    "print(f\"abc_accTest :- >> {abc_accTest}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9140ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
