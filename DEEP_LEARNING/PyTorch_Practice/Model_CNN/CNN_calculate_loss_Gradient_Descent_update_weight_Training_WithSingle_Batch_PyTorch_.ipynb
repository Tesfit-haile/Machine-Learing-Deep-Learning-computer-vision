{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f76e1d96",
   "metadata": {},
   "source": [
    "# Training with Single batch, PyTorch CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e29f1a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a0ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(NetWork, self).__init__()\n",
    "        \n",
    "        #### conv layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)  \n",
    "        \n",
    "        #### Linear layers\n",
    "        self.fc1 = nn.Linear(in_features= 12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120 , out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "            \n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = t #input layer\n",
    "        \n",
    "        #### hidden conv1 layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        #### hidden conv2 layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        #### hidden Linear_1 layer\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #### hidden Linear_2 layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        #### hidden Linear_out layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862b89f",
   "metadata": {},
   "source": [
    "#### Fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9279e22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    './FashionMNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()]) # converting ToTensor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec67555",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0b30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28584b2d",
   "metadata": {},
   "source": [
    "#### Create a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00b6022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "images, labels = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeaac30",
   "metadata": {},
   "source": [
    "#### Initiate the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42767c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NetWork()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24e649",
   "metadata": {},
   "source": [
    "## Calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e845c254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3097, grad_fn=<NllLossBackward0>) \n",
      " 2.309678077697754\n"
     ]
    }
   ],
   "source": [
    "#### lets pass the images to the network and get the prediction\n",
    "preds = network(images)\n",
    "\n",
    "#### then we are going to access the cross_entropy loss func from the PyTorch  functional API\n",
    "loss = F.cross_entropy(preds, labels)\n",
    "print(loss, '\\n', loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fdc16a",
   "metadata": {},
   "source": [
    "# Calculate the Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ca578b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#### First lets check our original gradients value\n",
    "print(network.conv1.weight.grad) # will return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24486969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now lets run our loss func when by using the back-propagation\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3fb961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "#### Now lets see the grad\n",
    "print(network.conv1.weight.grad.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f202a",
   "metadata": {},
   "source": [
    "### Our gradient had been updated . ðŸ‘†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1db341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49bfbeb3",
   "metadata": {},
   "source": [
    "# Now Use the Gradients & Update the NN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0383adc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2656915187835693"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### network.parameters() ----> are the weithts\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01) \n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d28011e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### will calu the num of correct prediction out of the batch_size\n",
    "def get_num_corrected(pred, labels):\n",
    "    return pred.argmax(dim=1).eq(labels).sum().item()\n",
    "get_num_corrected(preds, labels)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8818920c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compaireIT = preds.argmax(dim=1).eq(labels).sum().item()\n",
    "compaireIT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb66fa",
   "metadata": {},
   "source": [
    "# Update the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95a237cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()  #### updating the weights of our NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af006011",
   "metadata": {},
   "source": [
    "#### To illustrate this feed the NN the same images and check the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15e18743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2656915187835693"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_2 = network(images)\n",
    "loss = F.cross_entropy(preds_2, labels)\n",
    "loss.item() # we will get less loss than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13c3d152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### check the num of correct prediction\n",
    "get_num_corrected(preds_2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd5062",
   "metadata": {},
   "source": [
    "# Training with Single batch, \n",
    "#### all the above cells in one cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bee3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.01\n",
      "    weight_decay: 0\n",
      ")\n",
      "loss: 1.7236833572387695\n",
      "loss: 1.5216926336288452\n"
     ]
    }
   ],
   "source": [
    "#### Train_loader and #### optimizer\n",
    "train_loader_2 = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
    "loss_2 = optim.Adam(network.parameters(), lr=0.01) # network.parameters() --> are weights\n",
    "print(loss_2)\n",
    "#### batch\n",
    "batch_2 = next(iter(train_loader))\n",
    "images_2, labels_2 = batch_2\n",
    "\n",
    "#### preds\n",
    "preds_2 = network(images_2) # predi by passing the images_2\n",
    "\n",
    "#### loss\n",
    "loss_2 = F.cross_entropy(preds_2, labels_2) # calculate loss\n",
    "\n",
    "#### loss-backwar\n",
    "loss_2.backward() # calcu gradient\n",
    "\n",
    "#### optimizer-step\n",
    "optimizer.step() # update weight\n",
    "\n",
    "\n",
    "print(f'loss: {loss_2.item()}')\n",
    "\n",
    "preds_3 = network(images_2)\n",
    "loss_3 = F.cross_entropy(preds_3, labels_2)\n",
    "\n",
    "print(f'loss: {loss_3.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a951e69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
