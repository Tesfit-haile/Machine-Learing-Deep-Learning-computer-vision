{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c091c0b3",
   "metadata": {},
   "source": [
    "# Formula of updating weights during the backpropagations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8daf5fb",
   "metadata": {},
   "source": [
    "# The Learning rate tells the optimizer how much step to go down or up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff95cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.9 64-bit' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#################  w_new = w_old - lr*gradient(derivativeOFloss / derivativeOF w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee1dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# what is the difference between F.relu and nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077257ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 55643\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "device = 'GPU' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2432d1",
   "metadata": {},
   "source": [
    "# Hyperparameters are:-- input_size, out_size, kernel_size, learinig_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa4f9bc",
   "metadata": {},
   "source": [
    "# Parameters are:- weihgts and bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bec407",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365bb23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArteficialNeuralNetwork(\n",
       "  (lin_1): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (lin_2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_layers = 100\n",
    "num_classes = 10\n",
    "lr = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "class ArteficialNeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ArteficialNeuralNetwork, self).__init__()\n",
    "        \n",
    "        self.lin_1 = nn.Linear(in_features=input_size, out_features=hidden_layers)\n",
    "        self.relu  = nn.ReLU() # we can also use instead of here inside of the forward func [F.relu(out)]\n",
    "        self.lin_2 = nn.Linear(in_features=hidden_layers, out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.lin_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.lin_2(out)\n",
    "        return out\n",
    "    \n",
    "ANN_model = ArteficialNeuralNetwork()\n",
    "ANN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0608b2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a569f8ae",
   "metadata": {},
   "source": [
    "# CNN\n",
    "# Be Care full will the kernel_size ,  stride, padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0cd821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Parameters\n",
    "input_size = 1 # it is one cuz we are dealing with white and black color image (gray scale images)\n",
    "num_classes = 10\n",
    "num_epoch  = 2  \n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=input_size, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # below the 16 comes from the out_channel how about the 7*7 ->  i think it is the height and width of the img\n",
    "        # it reduce from 28*28 to 7*7 b/c of the operation\n",
    "        self.fc1 = nn.Linear(in_features=16*7*7, out_features=num_classes) \n",
    "        # i think the \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.reshape(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "CNN_model = CNN().to(device)\n",
    "CNN_model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280bfc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "784\n"
     ]
    }
   ],
   "source": [
    "print(28*28)\n",
    "print(16*7*7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab629175",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e915ec3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (rnn): RNN(28, 128, num_layers=2, batch_first=True)\n",
       "  (fc1): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i think RNN take one row in a time not like CNN takes 784 at once(the whole pic)\n",
    "input_size = 28 \n",
    "sequence_len = 28 # optional. it might help you during the traing process\n",
    "hidden_size = 128 # you can chose any number\n",
    "num_classes = 10\n",
    "num_layers = 2\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = 'GPU' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "#### Model\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ##### i think here below we are initiating the (num_layers and hidden_size) klte layer with 128 nodes\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size) # not clear\n",
    "        #print('print from forward method >>>', len(h0[0][0]), len(h0[1][0]))\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc1(out)\n",
    "        return out\n",
    "    \n",
    "RNN_model = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "RNN_model  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e187e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "626a72c7",
   "metadata": {},
   "source": [
    "# BRNN---- Bidirectional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eace004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BRNN(\n",
       "  (lstm): LSTM(28, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 28 \n",
    "sequence_len = 28 \n",
    "hidden_size = 128 # you can chose any number\n",
    "num_classes = 10\n",
    "num_layers = 2\n",
    "batch_size = 100\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001\n",
    "\n",
    "class BRNN(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_size):\n",
    "        super(BRNN, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # why times 2 ---- i think one it goes forward and the second goes backward\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return out \n",
    "    \n",
    "        #print(\"form BRNN...\", out.shape) --> torch.Size([100, 10] cuz it has to be passed through the fc\n",
    "        \n",
    "\n",
    "BRNN_model = BRNN(num_layers, hidden_size)\n",
    "BRNN_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb51f7d8",
   "metadata": {},
   "source": [
    "# ========================= Training=========================\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a322aa5",
   "metadata": {},
   "source": [
    "# Be care full on changing the optimizer for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430bfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### loss\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer = torch.optim.Adam(ANN_model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.Adam(CNN_model.parameters(), lr=learning_rate)\n",
    "# optimizer = torch.optim.Adam(RNN_model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(BRNN_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522909aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "training_data = torchvision.datasets.MNIST('dataMNIST/', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(), \n",
    "                                           #transform=transforms.Normalize(),\n",
    "                                           download=True)\n",
    "\n",
    "testing_data  = torchvision.datasets.MNIST('dataMNIST/', \n",
    "                                           train=False, \n",
    "                                           transform=transforms.ToTensor(), \n",
    "                                           #transform=transforms.Normalize(),\n",
    "                                           download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=testing_data, batch_size=batch_size, shuffle=True) \n",
    "# we've 10000 test samples and 60000 train samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f88e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "566ea44c",
   "metadata": {},
   "source": [
    "# Firts try it with single image always always...........\n",
    "##### if you see your loss function is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317ddd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n",
      "Loss-erorr: 2.3044614791870117\n"
     ]
    }
   ],
   "source": [
    "# if you see the loss error is getting lower and lower\n",
    "# this means your model is read to be traind\n",
    "\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "for epoch in range(12):\n",
    "    # ðŸ‘‰ðŸ‘‰ðŸ‘‰ try it first with on batch #\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    #print(images.shape, labels) #### we got 100 images with 100 labels and 1 means it's black and white(1 depth)\n",
    "    #torch.Size([100, 1, 28, 28])\n",
    "\n",
    "    #ANN_model ----- torch.Size([100, 128])\n",
    "    #images = images.reshape(-1, 28*28).to(device) # only for ANN_model  [input must have 2 dimensions]\n",
    "\n",
    "\n",
    "    #RNN_model & BRNN_model ---- torch.Size([100, 28, 28])\n",
    "    images = images.reshape(-1, 28, 28).to(device) # RNN_model & BRNN_model ---- [input must have 3 dimensions]\n",
    "\n",
    "\n",
    "    #forward\n",
    "    scores_pred = RNN_model(images)\n",
    "    loss = loss_func(scores_pred, labels)\n",
    "\n",
    "    #backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # gradient descent update step/adam step\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Loss-erorr: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca61db4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82330da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "468f6281",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882f4278",
   "metadata": {},
   "source": [
    "# Be care full on changing on the images.reshape for each model.....!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee49f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3045, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3113, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.2998, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3000, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3095, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3010, grad_fn=<NllLossBackward0>)\n",
      " >>> Accuracy on Training-data >> : 12.108333333333333\n",
      "tensor(2.3020, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3025, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3032, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3103, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3108, grad_fn=<NllLossBackward0>)\n",
      "tensor(2.3010, grad_fn=<NllLossBackward0>)\n",
      " >>> Accuracy on Training-data >> : 12.108333333333333\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    corr = 0\n",
    "    n_samples = 0\n",
    "    ix = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        #print(images.shape, labels) #### we got 100 images with 100 labels\n",
    "        #torch.Size([100, 1, 28, 28])\n",
    "        \n",
    "        #ANN_model ----- torch.Size([100, 128])\n",
    "        #images = images.reshape(-1, 28*28).to(device) # only for NN_model  [input must have 2 dimensions]\n",
    "\n",
    "        \n",
    "        #RNN_model & BRNN_model -- torch.Size([100, 28, 28])\n",
    "        images = images.reshape(-1, 28, 28).to(device) #only for RNN_model & BRNN_model --[input must have 3 dim]\n",
    "        \n",
    "        \n",
    "        #forward\n",
    "        scores_pred = RNN_model(images)\n",
    "        loss = loss_func(scores_pred, labels)\n",
    "\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent update step/adam step\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predictions = torch.max(scores_pred, 1)\n",
    "        good_pred = (predictions == labels).sum().item()\n",
    "        \n",
    "        corr += good_pred\n",
    "        n_samples += labels.size(0)\n",
    "        ix += 1\n",
    "    \n",
    "        if ix % 100 == 0:\n",
    "            print(loss)\n",
    "            \n",
    "    print(f\" >>> Accuracy on Training-data >> : {100 * corr / n_samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987037bc",
   "metadata": {},
   "source": [
    "# Testing the model ---> use [ with torch.no_grads ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b1dff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >>> Accuracy ON Testing-data >> : 12.16\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    corr = 0\n",
    "    n_samples = 0\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #print(images.shape, labels) #### we got 100 images with 100 labels\n",
    "        #torch.Size([100, 1, 28, 28])\n",
    "\n",
    "        #ANN_model ----- torch.Size([100, 128])\n",
    "        #images = images.reshape(-1, 28*28).to(device) # only for NN_model  [input must have 2 dimensions]\n",
    "\n",
    "\n",
    "        #RNN_model & BRNN_model ---- torch.Size([100, 28, 28])\n",
    "        images = images.reshape(-1, 28, 28).to(device) # RNN_model & BRNN_model ----[input must have 3 dimensions]\n",
    "\n",
    "\n",
    "        #forward\n",
    "        scores_pred = RNN_model(images)\n",
    "\n",
    "        _, predictions = torch.max(scores_pred, 1)\n",
    "        good_pred = (predictions == labels).sum().item()\n",
    "\n",
    "        corr += good_pred\n",
    "        n_samples += labels.size(0)\n",
    "\n",
    "    print(f\" >>> Accuracy ON Testing-data >> : {100 * corr / n_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d47f5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
