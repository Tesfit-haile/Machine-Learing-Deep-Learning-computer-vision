{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2e4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) design our model\n",
    "# 2) construct loss & optimi\n",
    "# 3) Training loop\n",
    "    # compute pred : forward pass\n",
    "    # gradients : backward pass\n",
    "    # update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518a827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78073315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: tensor([0., 0., 0., 0.], grad_fn=<MulBackward0>), Loss: 30.0\n",
      "Pred: tensor([1.6063, 3.2125, 4.8188, 6.4250], grad_fn=<MulBackward0>), Loss: 1.1627856492996216\n",
      "Pred: tensor([1.9225, 3.8450, 5.7674, 7.6899], grad_fn=<MulBackward0>), Loss: 0.0450688973069191\n",
      "Pred: tensor([1.9847, 3.9695, 5.9542, 7.9390], grad_fn=<MulBackward0>), Loss: 0.0017468547448515892\n",
      "Pred: tensor([1.9970, 3.9940, 5.9910, 7.9880], grad_fn=<MulBackward0>), Loss: 6.770494655938819e-05\n",
      "Pred: tensor([1.9994, 3.9988, 5.9982, 7.9976], grad_fn=<MulBackward0>), Loss: 2.6243997126584873e-06\n",
      "Pred: tensor([1.9999, 3.9998, 5.9997, 7.9995], grad_fn=<MulBackward0>), Loss: 1.0175587306093803e-07\n",
      "Pred: tensor([2.0000, 4.0000, 5.9999, 7.9999], grad_fn=<MulBackward0>), Loss: 3.9741685498029256e-09\n",
      "Pred: tensor([2.0000, 4.0000, 6.0000, 8.0000], grad_fn=<MulBackward0>), Loss: 1.4670220593870908e-10\n",
      "Pred: tensor([2.0000, 4.0000, 6.0000, 8.0000], grad_fn=<MulBackward0>), Loss: 5.076827847005916e-12\n",
      "The finall optimized Weight is: 1.9999996423721313\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "\n",
    "def forward(x):\n",
    "    return w * x\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD([w], lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    y_pred = forward(x)\n",
    "    \n",
    "    loss_func = loss(y, y_pred)\n",
    "    loss_func.backward()  # gradient descent for getting the derivative \n",
    "    \n",
    "    optimizer.step() #then update the weight !!!!\n",
    "    optimizer.zero_grad()#updating the old value\n",
    "    \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Pred: {y_pred}, Loss: {loss_func}\")\n",
    "\n",
    "        \n",
    "print(f\"The finall optimized Weight is: {w}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5353e",
   "metadata": {},
   "source": [
    "# 2 questions \n",
    "1. why my loss func is NOT keep reducing ?\n",
    "2. i can see my accuracy is 100% from the above, BUT is how can i calculate it in percent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0abb7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
